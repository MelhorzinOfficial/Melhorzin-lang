package lexer

import (
	"fmt"
	"strings"
	"unicode"
)

// TokenType define os tipos de tokens.
type TokenType string

const (
	TokenPrint       TokenType = "PRINT"       // üñ®Ô∏è
	TokenAssign      TokenType = "ASSIGN"      // ‚úçÔ∏è
	TokenEqual       TokenType = "EQUAL"       // üü∞
	TokenMain        TokenType = "MAIN"        // main
	TokenTry         TokenType = "TRY"         // üë®üèø‚Äçüíª
	TokenCatch       TokenType = "CATCH"       // ü§¶üèø‚Äç‚ôÇÔ∏è
	TokenTryStart    TokenType = "TRY_START"   // üöÄ
	TokenFunction    TokenType = "FUNCTION"    // ‚ñ∂Ô∏è
	TokenReturn      TokenType = "RETURN"      // ‚Ü©Ô∏è
	TokenInterpolate TokenType = "INTERPOLATE" // üí±
	TokenMult        TokenType = "MULT"        // ‚úñÔ∏è
	TokenNumPlus     TokenType = "NUMPLUS"     // ‚ûï
	TokenConcat      TokenType = "CONCAT"      // .
	TokenIdentifier  TokenType = "IDENTIFIER"  // nomedavariavel
	TokenString      TokenType = "STRING"      // "texto"
	TokenNumber      TokenType = "NUMBER"      // 10
	TokenBoolean     TokenType = "BOOLEAN"     // true/false
	TokenLBrace      TokenType = "LBRACE"      // {
	TokenRBrace      TokenType = "RBRACE"      // }
	TokenLParen      TokenType = "LPAREN"      // (
	TokenRParen      TokenType = "RPAREN"      // )
	TokenComma       TokenType = "COMMA"       // ,
	TokenEqualSign   TokenType = "EQUALSIGN"   // =
	TokenPlus        TokenType = "PLUS"        // +
	TokenEOF         TokenType = "EOF"

	// Tokens for type system
	TokenTypeNumber TokenType = "TYPE_NUMBER" // üî¢
	TokenTypeString TokenType = "TYPE_STRING" // üìù
	TokenTypeBool   TokenType = "TYPE_BOOL"   // ‚öñÔ∏è
	TokenTypeAny    TokenType = "TYPE_ANY"    // üóëÔ∏è
	TokenTypeColon  TokenType = "TYPE_COLON"  // :
)

// Token representa um token com tipo e valor.
type Token struct {
	Type  TokenType
	Value string
}

// Lexer cont√©m o estado do lexer.
type Lexer struct {
	input  string
	pos    int
	tokens []Token
}

// NewLexer cria um novo lexer.
func NewLexer(input string) *Lexer {
	return &Lexer{input: input, pos: 0, tokens: []Token{}}
}

// Lex analisa o input e retorna os tokens.
func (l *Lexer) Lex() []Token {
	for l.pos < len(l.input) {
		// Ler a pr√≥xima sequ√™ncia de bytes como string para comparar emojis
		remaining := l.input[l.pos:]

		// Verificar emojis primeiro
		if strings.HasPrefix(remaining, "üñ®Ô∏è") {
			l.tokens = append(l.tokens, Token{Type: TokenPrint, Value: "üñ®Ô∏è"})
			l.pos += len("üñ®Ô∏è")
			continue
		}
		if strings.HasPrefix(remaining, "‚úçÔ∏è") {
			l.tokens = append(l.tokens, Token{Type: TokenAssign, Value: "‚úçÔ∏è"})
			l.pos += len("‚úçÔ∏è")
			continue
		}
		if strings.HasPrefix(remaining, "üü∞") {
			l.tokens = append(l.tokens, Token{Type: TokenEqual, Value: "üü∞"})
			l.pos += len("üü∞")
			continue
		}
		if strings.HasPrefix(remaining, "üë®üèø‚Äçüíª") {
			l.tokens = append(l.tokens, Token{Type: TokenTry, Value: "üë®üèø‚Äçüíª"})
			l.pos += len("üë®üèø‚Äçüíª")
			continue
		}
		if strings.HasPrefix(remaining, "ü§¶üèø‚Äç‚ôÇÔ∏è") {
			l.tokens = append(l.tokens, Token{Type: TokenCatch, Value: "ü§¶üèø‚Äç‚ôÇÔ∏è"})
			l.pos += len("ü§¶üèø‚Äç‚ôÇÔ∏è")
			continue
		}
		if strings.HasPrefix(remaining, string('üöÄ')) {
			l.tokens = append(l.tokens, Token{Type: TokenTryStart, Value: string('üöÄ')})
			l.pos += len(string('üöÄ'))
			continue
		}
		if strings.HasPrefix(remaining, "‚ñ∂Ô∏è") {
			l.tokens = append(l.tokens, Token{Type: TokenFunction, Value: "‚ñ∂Ô∏è"})
			l.pos += len("‚ñ∂Ô∏è")
			continue
		}
		if strings.HasPrefix(remaining, "‚Ü©Ô∏è") {
			l.tokens = append(l.tokens, Token{Type: TokenReturn, Value: "‚Ü©Ô∏è"})
			l.pos += len("‚Ü©Ô∏è")
			continue
		}
		if strings.HasPrefix(remaining, "‚úñÔ∏è") {
			l.tokens = append(l.tokens, Token{Type: TokenMult, Value: "‚úñÔ∏è"})
			l.pos += len("‚úñÔ∏è")
			continue
		}
		if strings.HasPrefix(remaining, "‚ûï") {
			l.tokens = append(l.tokens, Token{Type: TokenNumPlus, Value: "‚ûï"})
			l.pos += len("‚ûï")
			continue
		}
		if strings.HasPrefix(remaining, "üí±") {
			// N√£o precisamos tokenizar o emoji de interpola√ß√£o, a interpola√ß√£o ser√° tratada no parser
			l.pos += len("üí±")
			continue
		}
		// Type emojis
		if strings.HasPrefix(remaining, "üî¢") {
			l.tokens = append(l.tokens, Token{Type: TokenTypeNumber, Value: "üî¢"})
			l.pos += len("üî¢")
			continue
		}
		if strings.HasPrefix(remaining, "üìù") {
			l.tokens = append(l.tokens, Token{Type: TokenTypeString, Value: "üìù"})
			l.pos += len("üìù")
			continue
		}
		if strings.HasPrefix(remaining, "‚öñÔ∏è") {
			l.tokens = append(l.tokens, Token{Type: TokenTypeBool, Value: "‚öñÔ∏è"})
			l.pos += len("‚öñÔ∏è")
			continue
		}
		if strings.HasPrefix(remaining, "üóëÔ∏è") {
			l.tokens = append(l.tokens, Token{Type: TokenTypeAny, Value: "üóëÔ∏è"})
			l.pos += len("üóëÔ∏è")
			continue
		}

		// Ler o pr√≥ximo rune
		r := rune(l.input[l.pos])

		switch {
		case r == '{':
			l.tokens = append(l.tokens, Token{Type: TokenLBrace, Value: "{"})
			l.pos++
		case r == '}':
			l.tokens = append(l.tokens, Token{Type: TokenRBrace, Value: "}"})
			l.pos++
		case r == '(':
			l.tokens = append(l.tokens, Token{Type: TokenLParen, Value: "("})
			l.pos++
		case r == ')':
			l.tokens = append(l.tokens, Token{Type: TokenRParen, Value: ")"})
			l.pos++
		case r == ',':
			l.tokens = append(l.tokens, Token{Type: TokenComma, Value: ","})
			l.pos++
		case r == '=':
			l.tokens = append(l.tokens, Token{Type: TokenEqualSign, Value: "="})
			l.pos++
		case r == '+':
			l.tokens = append(l.tokens, Token{Type: TokenPlus, Value: "+"})
			l.pos++
		case r == '*':
			l.tokens = append(l.tokens, Token{Type: TokenMult, Value: "*"})
			l.pos++
		case r == '"':
			l.pos++
			start := l.pos
			stringContent := ""

			for l.pos < len(l.input) && l.input[l.pos] != '"' {
				// Verificar se temos uma interpola√ß√£o dentro da string
				if l.pos+2 < len(l.input) &&
					strings.HasPrefix(l.input[l.pos:], "üí±{") {
					// Adiciona o conte√∫do at√© aqui como uma string
					if l.pos > start {
						stringContent += l.input[start:l.pos]
					}

					// Adiciona o token de interpola√ß√£o
					l.tokens = append(l.tokens, Token{Type: TokenString, Value: stringContent})
					stringContent = "" // Reseta o conte√∫do

					// Avan√ßa al√©m do üí±{
					l.pos += len("üí±{")
					l.tokens = append(l.tokens, Token{Type: TokenInterpolate, Value: "üí±"})
					l.tokens = append(l.tokens, Token{Type: TokenLBrace, Value: "{"})

					// Captura o identificador dentro das chaves
					identStart := l.pos
					for l.pos < len(l.input) && l.input[l.pos] != '}' {
						l.pos++
					}

					if l.pos >= len(l.input) {
						fmt.Printf("Interpola√ß√£o n√£o terminada na posi√ß√£o %d\n", l.pos)
						return l.tokens
					}

					// Adiciona o identificador
					identifier := l.input[identStart:l.pos]
					l.tokens = append(l.tokens, Token{Type: TokenIdentifier, Value: identifier})
					l.tokens = append(l.tokens, Token{Type: TokenRBrace, Value: "}"})

					l.pos++ // Pula o }
					start = l.pos
					continue
				}

				l.pos++
			}

			// Adiciona qualquer texto restante como uma string
			if l.pos > start {
				stringContent += l.input[start:l.pos]
			}

			if l.pos >= len(l.input) {
				fmt.Printf("String n√£o terminada na posi√ß√£o %d\n", l.pos)
				return l.tokens
			}

			l.tokens = append(l.tokens, Token{Type: TokenString, Value: stringContent})
			l.pos++ // Pula o "
		case unicode.IsLetter(r):
			start := l.pos
			for l.pos < len(l.input) && (unicode.IsLetter(rune(l.input[l.pos])) || unicode.IsDigit(rune(l.input[l.pos]))) {
				l.pos++
			}
			value := l.input[start:l.pos]

			// Verificar palavras-chave e valores booleanos
			if value == "true" || value == "false" {
				l.tokens = append(l.tokens, Token{Type: TokenBoolean, Value: value})
			} else if value == "main" {
				l.tokens = append(l.tokens, Token{Type: TokenMain, Value: value})
			} else {
				l.tokens = append(l.tokens, Token{Type: TokenIdentifier, Value: value})
			}
			continue
		case unicode.IsDigit(r):
			start := l.pos
			for l.pos < len(l.input) && unicode.IsDigit(rune(l.input[l.pos])) {
				l.pos++
			}
			l.tokens = append(l.tokens, Token{Type: TokenNumber, Value: l.input[start:l.pos]})
			continue
		case unicode.IsSpace(r) || r == '\n' || r == '\r' || r == '\t':
			l.pos++ // Ignora espa√ßos, tabs e quebras de linha
		case r == 0xFE0F || r == 0xFEFF: // Ignora Variation Selector e BOM
			l.pos++
		case r == '.':
			l.tokens = append(l.tokens, Token{Type: TokenConcat, Value: "."})
			l.pos++
		case r == ':':
			l.tokens = append(l.tokens, Token{Type: TokenTypeColon, Value: ":"})
			l.pos++
		default:
			fmt.Printf("Caractere inesperado na posi√ß√£o %d: '%s' (Unicode: U+%X)\n", l.pos, string(r), r)
			l.pos++
		}
	}
	l.tokens = append(l.tokens, Token{Type: TokenEOF, Value: ""})
	fmt.Println("Tokens gerados:", l.tokens) // Log para depura√ß√£o
	return l.tokens
}
